package fingerprints

import (
	"fmt"
	"gopkg.in/yaml.v3"
	"os"
	"strings"
	"unicode"
)

// ============================================================================
// SECTION 1: YAML and Rule Structures
// ============================================================================

// RuleConfig æ˜ å°„äº† YAML æ–‡ä»¶ä¸­çš„å•æ¡è§„åˆ™ç»“æ„
type RuleConfig struct {
	Name       string `yaml:"name"`
	Path       string `yaml:"path"`
	Expression string `yaml:"expression"`
	Rank       int    `yaml:"rank"`
	Tag        string `yaml:"tag"`
	IsPost     bool   `yaml:"isPost"`
}

// CompiledRule å­˜å‚¨äº†ä» YAML åŠ è½½çš„é…ç½®ä»¥åŠè¢«è§£æåçš„ AST
type CompiledRule struct {
	RuleConfig
	AST Node
}

// ResponseData å­˜å‚¨ä»HTTPå“åº”ä¸­æå–çš„å…³é”®ä¿¡æ¯
type ResponseData struct {
	Headers string
	Body    string
	Hash    string // Icon Hash
	//å‰ä¸‰ä¸ªç”¨äºç»™Bannerä½¿ç”¨
	BodyLength int
	Cert       string
	Title      string
	ICP        string
	Host       string // ç”¨äºå­˜å‚¨è¯·æ±‚çš„ä¸»æœºåæˆ–IPåœ°å€
	//FoundDomain string
	//FoundIP     string
}

// MatchedResult å­˜å‚¨åŒ¹é…æˆåŠŸçš„ç»“æœ
type MatchedResult struct {
	Name string
	Rank int
	URL  string
}

// LoadRulesFromFile ä»æŒ‡å®šçš„ YAML æ–‡ä»¶è·¯å¾„åŠ è½½å¹¶ç¼–è¯‘æ‰€æœ‰è§„åˆ™
func LoadRulesFromFile(filepath string) ([]CompiledRule, error) {
	data, err := os.ReadFile(filepath)
	if err != nil {
		return nil, fmt.Errorf("failed to read rule file %s: %w", filepath, err)
	}

	var configs []RuleConfig
	if err := yaml.Unmarshal(data, &configs); err != nil {
		return nil, fmt.Errorf("failed to unmarshal yaml: %w", err)
	}

	var compiledRules []CompiledRule
	for _, config := range configs {
		// å¤ç”¨ä¹‹å‰çš„è¡¨è¾¾å¼è§£æå™¨
		ast, err := parseExpression(config.Expression)
		if err != nil {
			// æ·»åŠ è¯¦ç»†é”™è¯¯ä¿¡æ¯
			fmt.Printf("âš ï¸ Warning: Skipping rule '%s' due to parsing error\n", config.Name)
			fmt.Printf("  Expression: %s\n", config.Expression)
			fmt.Printf("  Error: %v\n", err)
			continue
		}
		compiledRules = append(compiledRules, CompiledRule{
			RuleConfig: config,
			AST:        ast,
		})
	}
	return compiledRules, nil
}

// ============================================================================
// SECTION 2: Parser Engine (Lexer, AST, Parser, Evaluator)
// ============================================================================

// TokenType, Token, Lexer...
type TokenType int

const (
	TokenError TokenType = iota
	TokenEOF
	TokenIdentifier
	TokenString
	TokenAnd
	TokenOr
	TokenEquals
	TokenNotEquals // æ–°å¢ != æ“ä½œç¬¦
	TokenLParen
	TokenRParen
)

type Token struct {
	Type  TokenType
	Value string
	Pos   int // æ·»åŠ ä½ç½®ä¿¡æ¯
}

type Lexer struct {
	input string
	pos   int
}

func NewLexer(input string) *Lexer { return &Lexer{input: input} }

// æ·»åŠ è¾…åŠ©æ–¹æ³•ï¼Œè·å–å½“å‰è¡Œå’Œåˆ—ä¿¡æ¯
func (l *Lexer) getPositionContext(pos int) string {
	if pos >= len(l.input) {
		return "end of input"
	}

	start := pos - 20
	if start < 0 {
		start = 0
	}
	end := pos + 20
	if end > len(l.input) {
		end = len(l.input)
	}

	context := l.input[start:end]
	pointerPos := pos - start

	// åˆ›å»ºæŒ‡å‘é”™è¯¯ä½ç½®çš„æŒ‡é’ˆ
	pointer := strings.Repeat(" ", pointerPos) + "^"

	return fmt.Sprintf("...%s...\n%s", context, pointer)
}

func (l *Lexer) nextToken() Token {
	l.skipWhitespace()
	if l.pos >= len(l.input) {
		return Token{Type: TokenEOF, Pos: l.pos}
	}
	char := l.input[l.pos]
	switch char {
	case '=':
		// æ£€æŸ¥æ˜¯å¦æ˜¯ == æˆ– =
		if l.pos+1 < len(l.input) && l.input[l.pos+1] == '=' {
			l.pos += 2
			return Token{Type: TokenEquals, Value: "==", Pos: l.pos - 2}
		}
		l.pos++
		return Token{Type: TokenEquals, Value: "=", Pos: l.pos - 1}
	case '!':
		// æ£€æŸ¥æ˜¯å¦æ˜¯ !=
		if l.pos+1 < len(l.input) && l.input[l.pos+1] == '=' {
			l.pos += 2
			return Token{Type: TokenNotEquals, Value: "!=", Pos: l.pos - 2}
		}
		errMsg := fmt.Sprintf("éæ³•å­—ç¬¦ '!' (0x21) åœ¨ä½ç½® %d", l.pos)
		errMsg += "\n" + l.getPositionContext(l.pos)
		return Token{Type: TokenError, Value: errMsg, Pos: l.pos}
	case '(':
		l.pos++
		return Token{Type: TokenLParen, Value: "(", Pos: l.pos - 1}
	case ')':
		l.pos++
		return Token{Type: TokenRParen, Value: ")", Pos: l.pos - 1}
	case '&':
		if l.pos+1 < len(l.input) && l.input[l.pos+1] == '&' {
			l.pos += 2 //ç›´æ¥åƒä¸¤ä¸ª
			return Token{Type: TokenAnd, Value: "&&", Pos: l.pos - 2}
		}
	case '|':
		if l.pos+1 < len(l.input) && l.input[l.pos+1] == '|' {
			l.pos += 2
			return Token{Type: TokenOr, Value: "||", Pos: l.pos - 2}
		}
	case '"':
		return l.readString()
	default:
		if unicode.IsLetter(rune(char)) || char == '<' || char == '>' {
			return l.readIdentifier()
		}
	}

	// åˆ›å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
	errMsg := fmt.Sprintf("éæ³•å­—ç¬¦ '%c' (0x%02x) åœ¨ä½ç½® %d", char, char, l.pos)
	errMsg += "\n" + l.getPositionContext(l.pos)
	return Token{Type: TokenError, Value: errMsg, Pos: l.pos}
}

func (l *Lexer) skipWhitespace() {
	for l.pos < len(l.input) && unicode.IsSpace(rune(l.input[l.pos])) {
		l.pos++
	}
}

func (l *Lexer) readIdentifier() Token {
	start := l.pos
	for l.pos < len(l.input) {
		char := l.input[l.pos]
		// å…è®¸å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œç‰¹æ®Šç¬¦å·
		if unicode.IsLetter(rune(char)) || unicode.IsDigit(rune(char)) ||
			char == '_' || char == '<' || char == '>' || char == '/' ||
			char == ':' || char == '.' || char == '-' {
			l.pos++
		} else {
			break
		}
	}
	return Token{Type: TokenIdentifier, Value: l.input[start:l.pos], Pos: start}
}

func (l *Lexer) readString() Token {
	start := l.pos
	l.pos++ // è·³è¿‡èµ·å§‹å¼•å·
	var sb strings.Builder

	for l.pos < len(l.input) {
		if l.input[l.pos] == '"' {
			l.pos++ // è·³è¿‡ç»“æŸå¼•å·
			return Token{Type: TokenString, Value: sb.String(), Pos: start}
		}

		// å¤„ç†è½¬ä¹‰å¼•å·
		if l.input[l.pos] == '\\' && l.pos+1 < len(l.input) {
			nextChar := l.input[l.pos+1]
			if nextChar == '"' || nextChar == '\\' {
				sb.WriteByte(nextChar)
				l.pos += 2
				continue
			}
		}

		sb.WriteByte(l.input[l.pos])
		l.pos++
	}

	// æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²é”™è¯¯
	errMsg := fmt.Sprintf("æœªç»ˆæ­¢çš„å­—ç¬¦ä¸²æ–‡æœ¬ï¼Œèµ·å§‹ä½ç½®: %d", start)
	errMsg += "\n" + l.getPositionContext(start)
	return Token{Type: TokenError, Value: errMsg, Pos: start}
}

// AST Nodes...
type Node interface{ Eval(data *ResponseData) bool }
type ConditionNode struct {
	Field    string
	Value    string
	Operator TokenType // æ·»åŠ æ“ä½œç¬¦å­—æ®µ
}

func (c *ConditionNode) Eval(data *ResponseData) bool {
	var targetValue string
	switch c.Field {
	case "body":
		targetValue = data.Body
	case "header":
		targetValue = data.Headers
	case "hash":
		targetValue = data.Hash
	default:
		return false
	}

	// æ ¹æ®æ“ä½œç¬¦è¿›è¡Œä¸åŒçš„åˆ¤æ–­
	switch c.Operator {
	case TokenEquals:
		return strings.Contains(targetValue, c.Value)
	case TokenNotEquals:
		return !strings.Contains(targetValue, c.Value)
	default:
		return false
	}
}

type BinaryOpNode struct {
	Operator    TokenType
	Left, Right Node
}

func (b *BinaryOpNode) Eval(data *ResponseData) bool {
	leftResult := b.Left.Eval(data)
	switch b.Operator {
	case TokenAnd:
		return leftResult && b.Right.Eval(data)
	case TokenOr:
		return leftResult || b.Right.Eval(data)
	}
	return false
}

// Parser...
type Parser struct {
	tokens []Token
	pos    int
}

func NewParser(tokens []Token) *Parser { return &Parser{tokens: tokens} }
func (p *Parser) current() Token {
	if p.pos < len(p.tokens) {
		return p.tokens[p.pos]
	}
	return Token{Type: TokenEOF}
}
func (p *Parser) advance() {
	if p.pos < len(p.tokens) {
		p.pos++
	}
}
func (p *Parser) expect(tt TokenType) (Token, error) {
	if p.current().Type == tt {
		t := p.current()
		p.advance()
		return t, nil
	}
	return Token{}, fmt.Errorf("è¯­æ³•é”™è¯¯: æœŸæœ› %v, ä½†å¾—åˆ° %v (ä½ç½®: %d)",
		tt, p.current().Type, p.current().Pos)
}
func (p *Parser) Parse() (Node, error) {
	n, err := p.parseExpression()
	if err != nil {
		return nil, err
	}
	if p.current().Type != TokenEOF {
		return nil, fmt.Errorf("è¯­æ³•é”™è¯¯: è¡¨è¾¾å¼å°¾éƒ¨æœ‰å¤šä½™å†…å®¹ '%s' (ä½ç½®: %d)",
			p.current().Value, p.current().Pos)
	}
	return n, nil
}
func (p *Parser) parseExpression() (Node, error) {
	l, e := p.parseTerm()
	if e != nil {
		return nil, e
	}
	for p.current().Type == TokenOr {
		op := p.current()
		p.advance()
		r, e := p.parseTerm()
		if e != nil {
			return nil, e
		}
		l = &BinaryOpNode{op.Type, l, r}
	}
	return l, nil
}
func (p *Parser) parseTerm() (Node, error) {
	l, e := p.parseFactor()
	if e != nil {
		return nil, e
	}
	for p.current().Type == TokenAnd {
		op := p.current()
		p.advance()
		r, e := p.parseFactor()
		if e != nil {
			return nil, e
		}
		l = &BinaryOpNode{op.Type, l, r}
	}
	return l, nil
}
func (p *Parser) parseFactor() (Node, error) {
	if p.current().Type == TokenLParen {
		p.advance()
		n, e := p.parseExpression()
		if e != nil {
			return nil, e
		}
		if _, e := p.expect(TokenRParen); e != nil {
			return nil, e
		}
		return n, nil
	}
	return p.parseCondition()
}
func (p *Parser) parseCondition() (Node, error) {
	ident, err := p.expect(TokenIdentifier)
	if err != nil {
		return nil, err
	}
	// åªä¿ç•™åŸå§‹å­—æ®µï¼šbody, header, hash
	validFields := map[string]bool{"body": true, "header": true, "hash": true}
	if !validFields[ident.Value] {
		return nil, fmt.Errorf("æ— æ•ˆå­—æ®µå: '%s' (ä½ç½®: %d)", ident.Value, ident.Pos)
	}

	// æ£€æŸ¥æ“ä½œç¬¦ç±»å‹ï¼ˆ= æˆ– !=ï¼‰
	var operator TokenType
	switch p.current().Type {
	case TokenEquals:
		operator = TokenEquals
		p.advance()
	case TokenNotEquals:
		operator = TokenNotEquals
		p.advance()
	default:
		return nil, fmt.Errorf("è¯­æ³•é”™è¯¯: æœŸæœ› = æˆ– !=, ä½†å¾—åˆ° %v (ä½ç½®: %d)",
			p.current().Type, p.current().Pos)
	}

	str, err := p.expect(TokenString)
	if err != nil {
		return nil, err
	}

	return &ConditionNode{
		Field:    ident.Value,
		Value:    str.Value,
		Operator: operator,
	}, nil
}

// parseExpression æ˜¯ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œå°è£…äº†å®Œæ•´çš„è¯æ³•å’Œè¯­æ³•åˆ†æè¿‡ç¨‹
func parseExpression(expression string) (Node, error) {
	lexer := NewLexer(expression)
	var tokens []Token
	for {
		tok := lexer.nextToken()
		if tok.Type == TokenError {
			return nil, fmt.Errorf("è¯æ³•é”™è¯¯: %s", tok.Value)
		}
		tokens = append(tokens, tok)
		if tok.Type == TokenEOF {
			break
		}
	}
	parser := NewParser(tokens)
	return parser.Parse()
}

func main() {
	//yamlPath := "fingerprints_fixed.yaml"
	yamlPath := "special.yaml"
	//host := "http://localhost:8080" //å¯¹è¿™ä¸ªhostè¿›è¡Œæ‰«ææ¢æµ‹
	fmt.Printf("ğŸ” Loading rules from %s \n", yamlPath)
	rules, err := LoadRulesFromFile(yamlPath)
	if err != nil {
		fmt.Printf("Error: %v\n", err)
		return
	}
	fmt.Printf("âœ…  Initial successfully,Loaded %d rules successfully.\n", len(rules))
	//for _, rule := range rules {
	//	url := host + rule.Path
	//	var sender Sender = &rule
	//	responseData, err := sender.Request(url, nil)
	//	if err != nil {
	//		log.Println("å‘åŒ…é”™è¯¯: " + err.Error())
	//	}
	//}
}

var compiledRule []CompiledRule

func init() {
	//åˆå§‹åŒ–
}
